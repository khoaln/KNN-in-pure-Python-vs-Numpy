{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Part 1: Implementation and evaluation of K-NN in pure python syntax\n",
    "(using basic data structures and functions in Python)**  \n",
    "1.1. Function _loadDataset_:  \n",
    "  + This function is to load the data from csv file\n",
    "  + Input: \n",
    "    - _filePath_: path to the csv file\n",
    "    - _trainPercentages_: percentages of test set\n",
    "  + Output:\n",
    "    - _dataset_: is a dict and devided into 4 parts: **x_train** contains all features from training set, **y_train** contains the class label (flower species) of\n",
    "training set and similarly, **x_test** contains all features of test set and **y_test** contains class label of the test set.\n",
    "  + Using **random.shuffle()** function: Because the data from csv file have been sorted by class label, we need to make it become random before deviding the dataset into training set and test set.  \n",
    "\n",
    "1.2. Function _calculateDistances_:\n",
    "  + This function is to calculate the distance between a test object and all other instances in the training dataset\n",
    "  + Input:\n",
    "    - _xTrain_: all features from training dataset\n",
    "    - _testObject_: test object from x_test\n",
    "  + Output:\n",
    "    - _distances_: list of Euclidean distances\n",
    "\n",
    "1.3. Function _findNeighbourLabels_:\n",
    "  + This function is to get a list of class labels from k-nearest neighbours of a test object\n",
    "  + Input:\n",
    "    - _xTrain_: all features from training set\n",
    "    - _yTrain_: class label from training set\n",
    "    - _testObject_: test object from x_test\n",
    "    - *k*: number of nearest neighbours\n",
    "  + Output:\n",
    "    - _neighbourLabels_: list of class labels\n",
    "  + Calling function **calculateDistances** to get a list of distances. Then sort the list of distances and get the index of the first *k* items in the sorted list. Return *k* labels from yTrain with the *k* indexes we just get.  \n",
    "\n",
    "1.4. Function _predictLabel_:\n",
    "  + This function is to find the most common label of the k-nearest neighbours\n",
    "  + Input:\n",
    "    - _neighbourLabels_: list of class labels of k-nearest neighbours\n",
    "  + Output:\n",
    "    - _mostCommon_: the most common label\n",
    "  + In the function, using a dict to store the counting number of values in **neighbourLabels**, then find the key of max value of the dict.\n",
    "\n",
    "1.5. Function _predictTestSet_:\n",
    "  + This function is to predict the class label of all instances in test set\n",
    "  + Input:\n",
    "    - _xTrain_: all features from training set\n",
    "    - _yTrain_: class label from training set\n",
    "    - _xTest_: all features from test set\n",
    "    - *k*: number of nearest neighbours\n",
    "  + Output:\n",
    "    - _predictLabels_: list of predicted labels of instances in test set\n",
    "  + For each instance in test set, call function **findNeighbourLabels** to find the class labels of k-nearest neighbours. Then call function **predictLabel** to predict class label for that test instance.\n",
    "\n",
    "1.6. Function _evaluate_:\n",
    "  + This function is to evaluate the accuracy of predictions by calculating ratio of the total correct predictions out of all predictions made.\n",
    "  + Input:\n",
    "    - _predictions_: list of predicted class labels of all instances in test set\n",
    "    - _yTest_: list of class labels of the test\n",
    "  + Output:\n",
    "    - _accuracy_: ratio of the total correct predictions out of all predictions made\n",
    "  + Count the number of the same values in the same index from **predictions** and **yTest**, then devide it by the number of intances in test set.\n",
    "\n",
    "1.7. Function _main_:\n",
    "  + Calls functions **loadDataset**, **predictTestSet** and **evaluate** in appropriate order to get the final result.\n",
    "  + Print the result in % correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98% correct\n",
      " "
     ]
    }
   ],
   "source": [
    "%%prun -s cumulative -l 30\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "def loadDataset(filePath, trainPercentages):\n",
    "    dataset = {'x_train': [], 'y_train': [], 'x_test': [], 'y_test': []}\n",
    "    with open(filePath, newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "        data = list(reader)\n",
    "        random.shuffle(data)\n",
    "        length = len(data)\n",
    "        splitPoint = int(length*trainPercentages)\n",
    "        for i in range(length):\n",
    "            features = [float(data[i][j]) for j in range(len(data[i]) - 1)]\n",
    "            label = int(data[i][-1])\n",
    "            if(i < splitPoint) :\n",
    "                dataset['x_train'].append(features)\n",
    "                dataset['y_train'].append(label)\n",
    "            else:\n",
    "                dataset['x_test'].append(features)\n",
    "                dataset['y_test'].append(label)\n",
    "            \n",
    "    return dataset            \n",
    "\n",
    "def calculateDistances(xTrain, testObject):\n",
    "    length = len(testObject)\n",
    "    distances = []\n",
    "    for x in xTrain:\n",
    "        sigma = 0\n",
    "        for i in range(length):\n",
    "            sigma += pow(x[i] - testObject[i], 2)\n",
    "        distances.append(math.sqrt(sigma))\n",
    "    \n",
    "    return distances\n",
    "\n",
    "def findNeighbourLabels(xTrain, yTrain, testObject, k):\n",
    "    distances = calculateDistances(xTrain, testObject)\n",
    "    sortedIndex = sorted(range(len(distances)), key=distances.__getitem__)\n",
    "    neighbourLabels = [yTrain[sortedIndex[i]] for i in range(k)]\n",
    "    return neighbourLabels\n",
    "\n",
    "def predictLabel(neighbourLabels):\n",
    "    labelCount = {0: 0, 1: 0, 2: 0}\n",
    "    for i in neighbourLabels:\n",
    "        labelCount[i] += 1\n",
    "    mostCommon = max(labelCount.keys(), key=lambda k: labelCount[k])\n",
    "    return mostCommon\n",
    "\n",
    "def predictTestSet(xTrain, yTrain, xTest, k):\n",
    "    predictLabels = [predictLabel(findNeighbourLabels(xTrain, yTrain, x, k)) for x in xTest]\n",
    "    return predictLabels\n",
    "\n",
    "def evaluate(predictions, yTest):\n",
    "    accuracy = 0\n",
    "    length = len(yTest)\n",
    "    for i in range(length):\n",
    "        if predictions[i] == yTest[i]:\n",
    "            accuracy += 1\n",
    "    accuracy = round(accuracy/length, 2)        \n",
    "    return accuracy     \n",
    "\n",
    "def main():\n",
    "    dataset = loadDataset('IRIS.csv', 0.66)\n",
    "    predictions = predictTestSet(dataset['x_train'], dataset['y_train'], \n",
    "                                 dataset['x_test'], 3)\n",
    "    accuracy = evaluate(predictions, dataset['y_test'])\n",
    "    print(\"Accuracy: {0}% correct\".format(int(accuracy*100)))\n",
    "    \n",
    "main()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Using %timeit magic command to check the execution time of each function**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "**Using %timeit magic command to check the execution time of each function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439 µs ± 9.12 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit loadDataset('IRIS.csv', 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.8 ms ± 113 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "dataset = loadDataset('IRIS.csv', 0.66)\n",
    "%timeit predictTestSet(dataset['x_train'], dataset['y_train'], dataset['x_test'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.18 µs ± 115 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "predictions = predictTestSet(dataset['x_train'], dataset['y_train'], \n",
    "                             dataset['x_test'], 3)\n",
    "%timeit evaluate(predictions, dataset['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 µs ± 2.08 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit findNeighbourLabels(dataset['x_train'], dataset['y_train'], dataset['x_test'][0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 µs ± 411 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit calculateDistances(dataset['x_train'], dataset['x_test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 µs ± 32.4 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "neighbourLabels = findNeighbourLabels(dataset['x_train'], dataset['y_train'], dataset['x_test'][0], 3)\n",
    "%timeit predictLabel(neighbourLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "**2. Part 2: Implementation and evaluation of K-NN in Numpy syntax (Using\n",
    "advanced data structures; Numpy and its functions).**  \n",
    "2.1. Function _npLoadDataset_:  \n",
    "  + This function is to load the data from csv file\n",
    "  + Input: \n",
    "    - _filePath_: path to the csv file\n",
    "    - _trainPercentages_: percentages of test set\n",
    "  + Output:\n",
    "    - _dataset_: is a dict and devided into 4 parts: **x_train** contains all features from training set, **y_train** contains the class label (flower species) of\n",
    "training set and similarly, **x_test** contains all features of test set and **y_test** contains class label of the test set.\n",
    "  + Using **np.random.shuffle** function: Because the data from csv file have been sorted by class label, we need to make it become random before deviding the dataset into training set and test set.  \n",
    "\n",
    "2.2. Function _npCalculateDistances_:\n",
    "  + This function is to calculate the distance between a test object and all other instances in the training dataset\n",
    "  + Input:\n",
    "    - _xTrain_: all features from training dataset\n",
    "    - _testObject_: test object from x_test\n",
    "  + Output:\n",
    "    - _distances_: array of Euclidean distances\n",
    "  + With numpy array, we can use the universal functions (np.square, np.sqrt ...) to do the calculations without the need of for loops. This helps the calculations run very fast.      \n",
    "\n",
    "2.3. Function _npFindNeighbourLabels_:\n",
    "  + This function is to get an array of class labels from k-nearest neighbours of a test object\n",
    "  + Input:\n",
    "    - _xTrain_: all features from training set\n",
    "    - _yTrain_: class label from training set\n",
    "    - _testObject_: test object from x_test\n",
    "    - *k*: number of nearest neighbours\n",
    "  + Output:\n",
    "    - _neighbourLabels_: numpy array of class labels\n",
    "  + Calling function **npCalculateDistances** to get an array of distances. Then sort the array of distances by using the **np.argsort** function, then slice the result to get the index of the first *k* items in the sorted list. Return *k* labels from yTrain with the *k* indexes we just found.  \n",
    "\n",
    "2.4. Function _npPredictLabel_:\n",
    "  + This function is to find the most common label of the k-nearest neighbours\n",
    "  + Input:\n",
    "    - _neighbourLabels_: list of class labels of k-nearest neighbours\n",
    "  + Output:\n",
    "    - _mostCommon_: the most common label\n",
    "  + In the function, using function **np.bincount** to count number of occurrences of each value in array **neighbourLabels**, then find the key of max value by using function **np.argmax**.\n",
    "\n",
    "2.5. Function _npPredictTestSet_:\n",
    "  + This function is to predict the class label of all instances in test set\n",
    "  + Input:\n",
    "    - _xTrain_: all features from training set\n",
    "    - _yTrain_: class label from training set\n",
    "    - _xTest_: all features from test set\n",
    "    - *k*: number of nearest neighbours\n",
    "  + Output:\n",
    "    - _predictLabels_: array of predicted labels of instances in test set\n",
    "  + For each instance in test set, call function **npFindNeighbourLabels** to find the class labels of k-nearest neighbours. Then call function **npPredictLabel** to predict class label for that test instance.\n",
    "\n",
    "2.6. Function _npEvaluate_:\n",
    "  + This function is to evaluate the accuracy of predictions by calculating ratio of the total correct predictions out of all predictions made.\n",
    "  + Input:\n",
    "    - _predictions_: array of predicted class labels of all instances in test set\n",
    "    - _yTest_: array of class labels of the test\n",
    "  + Output:\n",
    "    - _accuracy_: ratio of the total correct predictions out of all predictions made\n",
    "  + Using function **np.sum** to get the total number of the same values in the same index from **predictions** and **yTest**, then devide it by the number of intances in test set.\n",
    "\n",
    "2.7. Function _npMain_:\n",
    "  + Calls functions **nploadDataset**, **npPredictTestSet** and **npEvaluate** in appropriate order to get the final result.\n",
    "  + Print the result in % correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98% correct\n",
      " "
     ]
    }
   ],
   "source": [
    "%%prun -s cumulative -l 30\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def npLoadDataset(filePath, trainPercentages):\n",
    "    df = pd.read_csv(filePath, header=None)\n",
    "    data = df.values\n",
    "    np.random.shuffle(data)\n",
    "    dataset = {}\n",
    "    splitPoint = int(data.shape[0]*trainPercentages)\n",
    "    dataset['x_train'] = data[:splitPoint, :4]\n",
    "    dataset['y_train'] = data[:splitPoint, 4].astype(int)\n",
    "    dataset['x_test'] = data[splitPoint:, :4]\n",
    "    dataset['y_test'] = data[splitPoint:, 4].astype(int)\n",
    "    return dataset\n",
    "    \n",
    "def npCalculateDistances(xTrain, testObject):\n",
    "    subtract = np.subtract(xTrain, testObject)\n",
    "    square = np.square(subtract)\n",
    "    distances = np.sqrt(np.sum(square, axis=1))\n",
    "    return distances\n",
    "    \n",
    "def npFindNeighbourLabels(xTrain, yTrain, testObject, k):\n",
    "    distances = npCalculateDistances(xTrain, testObject)\n",
    "    sortedIndex = np.argsort(distances)\n",
    "    neighboursIndex = sortedIndex[:k]\n",
    "    neighbourLabels = yTrain[neighboursIndex]\n",
    "    return neighbourLabels\n",
    "\n",
    "def npPredictLabel(neighbourLabels):\n",
    "    counts = np.bincount(neighbourLabels)\n",
    "    mostCommon = np.argmax(counts)\n",
    "    return mostCommon\n",
    "\n",
    "def npPredictTestSet(xTrain, yTrain, xTest, k):\n",
    "    predictLabels = [npPredictLabel(npFindNeighbourLabels(xTrain, yTrain, x, k)) for x in xTest]\n",
    "    return predictLabels\n",
    "\n",
    "def npEvaluate(predictions, yTest):\n",
    "    accuracy = np.sum(predictions == yTest)\n",
    "    length = yTest.size;\n",
    "    return round(accuracy/length, 2) \n",
    "    \n",
    "def npMain():\n",
    "    dataset = npLoadDataset('IRIS.csv', 0.66)\n",
    "    predictions = npPredictTestSet(dataset['x_train'], dataset['y_train'], \n",
    "                                   dataset['x_test'], 3)\n",
    "    accuracy = npEvaluate(predictions, dataset['y_test'])\n",
    "    print(\"Accuracy: {0}% correct\".format(int(accuracy*100)))\n",
    "    \n",
    "npMain()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Using %timeit magic command to check the execution time of each function**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "**Using %timeit magic command to check the execution time of each function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26 ms ± 10.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pd.read_csv('IRIS.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.49 ms ± 19.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit npLoadDataset('IRIS.csv', 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873 µs ± 15.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "dataset = npLoadDataset('IRIS.csv', 0.66)\n",
    "%timeit npPredictTestSet(dataset['x_train'], dataset['y_train'], dataset['x_test'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.1 µs ± 64.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "predictions = npPredictTestSet(dataset['x_train'], dataset['y_train'], dataset['x_test'], 3)\n",
    "%timeit npEvaluate(predictions, dataset['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.3 µs ± 236 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit npFindNeighbourLabels(dataset['x_train'], dataset['y_train'], dataset['x_test'][0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.63 µs ± 118 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit npCalculateDistances(dataset['x_train'], dataset['x_test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.42 µs ± 7.41 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "neighbourLabels = npFindNeighbourLabels(dataset['x_train'], dataset['y_train'], dataset['x_test'][0], 3)\n",
    "%timeit npPredictLabel(neighbourLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "**3. Part 3: Compare the performance of the implemented algorithms based on\n",
    "their execution times.**\n",
    "  + **_Profiling of the implementation in part 1:_**\n",
    "  ```\n",
    "  32073 function calls in 0.241 seconds\n",
    "\n",
    "   Ordered by: cumulative time\n",
    "   List reduced from 48 to 30 due to restriction <30>\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        1    0.000    0.000    0.241    0.241 {built-in method builtins.exec}\n",
    "        1    0.000    0.000    0.240    0.240 <string>:2(<module>)\n",
    "        1    0.000    0.000    0.240    0.240 <string>:63(main)\n",
    "        1    0.000    0.000    0.231    0.231 <string>:50(predictTestSet)\n",
    "        1    0.001    0.001    0.231    0.231 <string>:51(<listcomp>)\n",
    "       51    0.001    0.000    0.228    0.004 <string>:37(findNeighbourLabels)\n",
    "       51    0.115    0.002    0.225    0.004 <string>:26(calculateDistances)\n",
    "    20196    0.073    0.000    0.073    0.000 {built-in method builtins.pow}\n",
    "     5349    0.019    0.000    0.019    0.000 {method 'append' of 'list' objects}\n",
    "     5049    0.018    0.000    0.018    0.000 {built-in method math.sqrt}\n",
    "        1    0.003    0.003    0.009    0.009 <string>:6(loadDataset)\n",
    "        1    0.001    0.001    0.003    0.003 random.py:261(shuffle)\n",
    "      149    0.002    0.000    0.003    0.000 random.py:223(_randbelow)\n",
    "       51    0.001    0.000    0.002    0.000 <string>:43(predictLabel)\n",
    "       51    0.001    0.000    0.001    0.000 {built-in method builtins.max}\n",
    "       51    0.001    0.000    0.001    0.000 {built-in method builtins.sorted}\n",
    "      255    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
    "      150    0.001    0.000    0.001    0.000 <string>:15(<listcomp>)\n",
    "      209    0.001    0.000    0.001    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
    "        1    0.000    0.000    0.001    0.001 {built-in method builtins.print}\n",
    "        2    0.000    0.000    0.001    0.000 iostream.py:366(write)\n",
    "      153    0.001    0.000    0.001    0.000 <string>:47(<lambda>)\n",
    "        3    0.000    0.000    0.001    0.000 iostream.py:195(schedule)\n",
    "      149    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
    "        3    0.000    0.000    0.000    0.000 socket.py:333(send)\n",
    "       51    0.000    0.000    0.000    0.000 <string>:40(<listcomp>)\n",
    "        2    0.000    0.000    0.000    0.000 iostream.py:313(_schedule_flush)\n",
    "       51    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
    "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
    "        3    0.000    0.000    0.000    0.000 threading.py:1104(is_alive) \n",
    "  ```\n",
    "  <br/>\n",
    "  + **_Profiling of the implementation in part 2:_**\n",
    "  ```\n",
    "  3334 function calls (3298 primitive calls) in 0.030 seconds\n",
    "\n",
    "   Ordered by: cumulative time\n",
    "   List reduced from 365 to 30 due to restriction <30>\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        1    0.000    0.000    0.030    0.030 {built-in method builtins.exec}\n",
    "        1    0.000    0.000    0.029    0.029 <string>:2(<module>)\n",
    "        1    0.000    0.000    0.029    0.029 <string>:44(npMain)\n",
    "        1    0.000    0.000    0.022    0.022 <string>:5(npLoadDataset)\n",
    "        1    0.000    0.000    0.020    0.020 parsers.py:542(parser_f)\n",
    "        1    0.000    0.000    0.020    0.020 parsers.py:414(_read)\n",
    "        1    0.000    0.000    0.018    0.018 parsers.py:1029(read)\n",
    "        1    0.000    0.000    0.017    0.017 frame.py:334(__init__)\n",
    "        1    0.000    0.000    0.017    0.017 frame.py:426(_init_dict)\n",
    "      3/2    0.000    0.000    0.008    0.004 series.py:165(__init__)\n",
    "        1    0.000    0.000    0.007    0.007 frame.py:7308(_arrays_to_mgr)\n",
    "        1    0.000    0.000    0.007    0.007 <string>:35(npPredictTestSet)\n",
    "        1    0.000    0.000    0.007    0.007 <string>:36(<listcomp>)\n",
    "        9    0.000    0.000    0.006    0.001 base.py:4897(_ensure_index)\n",
    "        1    0.000    0.000    0.005    0.005 series.py:283(_init_dict)\n",
    "       51    0.001    0.000    0.004    0.000 <string>:23(npFindNeighbourLabels)\n",
    "        1    0.000    0.000    0.004    0.004 internals.py:4869(create_block_manager_from_arrays)\n",
    "      607    0.002    0.000    0.003    0.000 {built-in method builtins.isinstance}\n",
    "        2    0.000    0.000    0.003    0.001 {pandas._libs.lib.clean_index_list}\n",
    "        1    0.000    0.000    0.003    0.003 internals.py:4880(form_blocks)\n",
    "      4/3    0.000    0.000    0.003    0.001 base.py:250(__new__)\n",
    "      8/2    0.000    0.000    0.003    0.001 <frozen importlib._bootstrap>:966(_find_and_load)\n",
    "        2    0.000    0.000    0.002    0.001 base.py:2430(equals)\n",
    "       51    0.001    0.000    0.002    0.000 <string>:17(npCalculateDistances)\n",
    "      8/2    0.000    0.000    0.002    0.001 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)\n",
    "      6/2    0.000    0.000    0.002    0.001 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
    "      6/2    0.000    0.000    0.002    0.001 {built-in method builtins.__import__}\n",
    "       51    0.001    0.000    0.002    0.000 <string>:30(npPredictLabel)\n",
    "      102    0.001    0.000    0.002    0.000 fromnumeric.py:50(_wrapfunc)\n",
    "        2    0.000    0.000    0.002    0.001 missing.py:376(array_equivalent)\n",
    "  ```\n",
    "<br/>\n",
    "  + **_The results from profiling and using %timeit magic command show that:_**\n",
    "    - Both implementations have the result of good classification accuracy (above 90% correct, typically 96% or better.), but the implementation with NumPy is much faster in total(0.03s vs 0.241s)\n",
    "    - In the algorithm implementation with NumPy, the distances between a test object and all other intances in the training set are calculated in 8.63 µs, ~14 times fater than the implementation withour NumPy (118 µs). The reason of this is because we can call the fast operations on entire **ndarray** of data without having to write loops, which is slow in the implementation with pure Python. \n",
    "    - Since the function to calculate the distances with NumPy is much faster than without NumPy, then the functions to find neightbour labels and predict all of test set, and also the entire implementation with Numpy are much faster than without NumPy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
